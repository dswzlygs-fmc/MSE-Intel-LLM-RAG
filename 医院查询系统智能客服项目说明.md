# 医院查询系统智能客服项目说明

## 项目分工

| 序号 |    姓名（学号）     | 项目分工              |
| ---- | :-----------------: | :-------------------- |
| 1    | 高幼骏(22262010010) | 技术实现、答辩        |
| 2    |  陶鑫(23262010026)  | 项目文档编辑、PPT编辑 |



## 一、方案介绍

### 背景

随着医疗信息化的快速发展，医院系统积累了大量的结构化和非结构化数据。患者和医务人员对于一个能够快速、准确地查询和分析这些数据的系统需求日益增长。

### 挑战

- 现有系统无法有效处理复杂的医疗数据查询。
- 用户界面不友好，缺乏自然语言交互能力。

### 目标

开发一个基于先进语言模型的智能客服，以简化医院查询流程，提供实时、准确的医疗信息。

## 二、技术特点

### LangChain 框架

- LangChain 是一个用于构建和部署基于大型语言模型（LLMs）的应用程序的框架。它提供了一系列工具和接口，使得开发者能够更容易地利用LLMs的能力来创建各种应用，如聊天机器人、问答系统等。

### 核心语言模型 (LLMs)

- 使用 阿里通义千问qwen模型，结合深度学习和自然语言处理技术。
- 通过定制化训练，优化模型以适应医疗领域的特定需求。

### RAG（检索增强生成）技术

- 结合检索系统和生成模型，提高查询的准确性和相关性。
- 特别适合处理医疗领域的复杂查询。

### Neo4j 图数据库
- 利用图数据库的高效模式匹配能力，优化复杂关系查询。
- 存储和检索医疗数据，如患者信息、医院信息、医生排班等。

### FastAPI 和 Streamlit
- 使用 FastAPI 创建 RESTful API，提供后端服务。
- 利用 Streamlit 构建交互式用户界面，提升用户体验。

## 三、*使用到的 Intel 软硬件技术

- ### Intel® Extension for Transformers

    - **模型优化与加速：** 利用 Intel® Extension for Transformers 实现基于 Transformer 模型的优化，以提高在 Intel 硬件平台上的性能。

    - 通过扩展 Hugging Face Transformer API和Intel® Neural Compressor，在基于 Transformer 的模型上提供无感的模型压缩优化功能， 结合自带的纯 C/C++ 开发的大型语言模型 (LLM) 推理引擎，对常见的LLM提供推理加速功能。

        · ITREX/NeuralChat: 一个可定制的聊天机器人框架，可利用知识检索、语音交互、查询缓存和安全防护等丰富的插件在几分钟内创建您自己的聊天机器人。该框架支持Intel Gaudi2/CPU/GPU。
- ### 与Langchain的集成
  - 本实验借用了LangChain中的 langchain.chains.GraphCypherQAChain，为了将Intel加载的大模型可以直接使用该链，需要创建一个类，将两者融合起来。
  - 具体做法是，创建一个子类，继承 langchain_core.language_models.llms.LLM，并将 intel_extension_for_transformers.neural_chat.models.chatglm_model.ChatGlmModel 作为参数传入，接受大模型的具体操作

    ![alt text](image.png)

    ![alt text](image-3.png)

## 四、成果说明和对照（）

###前期数据准备

![image-20240501102402925](医院查询系统智能客服项目说明.assets/image-20240501102402925.png)

###项目框架图

![image-20240430215129342](医院查询系统智能客服项目说明.assets/image-20240430215129342.png)

###核心代码：

![image-20240430214229441](医院查询系统智能客服项目说明.assets/image-20240430214229441.png)

**cypher_llm**： 用于生成 Cypher 查询的 LLM

**qa_llm**: 用于生成问答的 LLM

**qa_prompt**: 用于问答生成的提示模板

**cypher_prompt**: 用于 Cypher 查询生成的提示模板

前端界面：

![image-20240430214102124](医院查询系统智能客服项目说明.assets/image-20240430214102124.png)

后端数据：

![image-20240430214126662](医院查询系统智能客服项目说明.assets/image-20240430214126662.png)

## 五、代码地址

**git clone https://oauth2:xc2HzTGebys5JoJKvELc@www.modelscope.cn/studios/dswzlygs/Intel_RagNeo4j.git**

## 六、关键文件说明

### Jupyter笔记文件
    1、前置准备.ipynb ：记录Ollama与Neo4j等基础组件安装配置步骤
    2、Neo4jChain-本地Windows-Ollama：记录Windows环境下调用Ollama实现的效果
    3、Intel环境准备-魔搭Linux环境.ipynb：记录在魔搭社区Notebook环境下的初始化步骤，包括针对build_chatbot返回大模型的封装测试
    4、NeuralChat-魔搭Linux-IntelNeuralChat：记录启用Intel相关方法后的调用效果
    5、基于Streamlit的交互式界面：记录Windows环境下调用Ollama实现的前端聊天效果

### Python代码
    Local_Ollama_Neo4jServer.py：基于FastAPI的后端服务，封装了关于Neo4j数据库的相关操作

    Streamlit-Chatbox.py：基于Streamlit的前端聊天界面

### PPT汇报文稿
    医院查询系统聊天智能客服.pptx



